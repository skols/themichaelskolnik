{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 *Learn Maching Learning* series on Kaggle\n",
    "This is the level 2 part of the *Learn Machine Learning* series on Kaggle using Python (https://www.kaggle.com/learn/machine-learning). The data used is from the [*Home Prices: Advanced Regression Techniques*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) competition.\n",
    "\n",
    "Like the post for level 1, this post will show the section name, my code from the corresponding section for the instructions under **Your Turn**, and some brief notes on what is taught in each section.\n",
    "\n",
    "First I'll run the necessary code from before and add a new function, score_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Save filepath to variable\n",
    "training_data_filepath = \"C:/Development/Kaggle/House Prices - Advanced \\\n",
    "Regression Techniques/train.csv\"\n",
    "\n",
    "# Read the data and store in a dataframe called training_set\n",
    "training_set = pd.read_csv(training_data_filepath)\n",
    "\n",
    "# Select the target variable and call it y\n",
    "y = training_set.SalePrice\n",
    "\n",
    "# Create a list of the predictor variables\n",
    "# predictors = [\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\",\n",
    "#               \"BedroomAbvGr\", \"TotRmsAbvGrd\"]\n",
    "\n",
    "# Create the dataframe with only numeric predictors\n",
    "# X = training_set[predictors]\n",
    "X = training_set.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "# Split data into training and validation data, for both predictors and\n",
    "# target.\n",
    "# The split is based on a random number generator. Supplying a numeric value\n",
    "# to the random_state argument guarantees we get the same split every time we\n",
    "# run this script. It can be any number; I'm choosing 42.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,\n",
    "                                                 train_size=0.7,\n",
    "                                                 test_size=0.3)\n",
    "\n",
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "[Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values)\n",
    "\n",
    "This section teaches multiple approaches for dealing with missing data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                 0\n",
      "MSSubClass         0\n",
      "LotFrontage      259\n",
      "LotArea            0\n",
      "OverallQual        0\n",
      "OverallCond        0\n",
      "YearBuilt          0\n",
      "YearRemodAdd       0\n",
      "MasVnrArea         8\n",
      "BsmtFinSF1         0\n",
      "BsmtFinSF2         0\n",
      "BsmtUnfSF          0\n",
      "TotalBsmtSF        0\n",
      "1stFlrSF           0\n",
      "2ndFlrSF           0\n",
      "LowQualFinSF       0\n",
      "GrLivArea          0\n",
      "BsmtFullBath       0\n",
      "BsmtHalfBath       0\n",
      "FullBath           0\n",
      "HalfBath           0\n",
      "BedroomAbvGr       0\n",
      "KitchenAbvGr       0\n",
      "TotRmsAbvGrd       0\n",
      "Fireplaces         0\n",
      "GarageYrBlt       81\n",
      "GarageCars         0\n",
      "GarageArea         0\n",
      "WoodDeckSF         0\n",
      "OpenPorchSF        0\n",
      "EnclosedPorch      0\n",
      "3SsnPorch          0\n",
      "ScreenPorch        0\n",
      "PoolArea           0\n",
      "MiscVal            0\n",
      "MoSold             0\n",
      "YrSold             0\n",
      "SalePrice          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detect which columns have missing values\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from dropping columns with missing values:\n",
      "1094.2438356164384\n"
     ]
    }
   ],
   "source": [
    "# Get model score from dropping columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"Mean Absolute Error from dropping columns with missing values:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation:\n",
      "1075.4383561643833\n"
     ]
    }
   ],
   "source": [
    "# Get model score from Imputation\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "\n",
    "# \"fit_transform\" is the training step. It \"learns\" based upon the training set data.\n",
    "# \"transform\" uses the newly trained model to make predictions on the \"test set\"\n",
    "# (a.k.a. \"validation set\" in the the first tutorial).\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation while tracking what was imputed:\n",
      "1027.7054794520548\n"
     ]
    }
   ],
   "source": [
    "# Get model score from Imputation with extra columns showing what was imputed\n",
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "\n",
    "cols_with_missing = (col for col in X_train.columns\n",
    "                    if X_train[col].isnull().any())\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + \"_was_missing\"] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + \"_was_missing\"] = imputed_X_test_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\n",
    "imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation while tracking what was imputed:\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))"
   ]
  }
 ],
 "metadata": {
  "front-matter": {
   "date": "2018-03-28",
   "slug": "home-prices-python-2",
   "subtitle": "",
   "title": "My code from the exercises of Level 2 of Kaggle's Learn Maching Learning series"
  },
  "hugo-jupyter": {
   "render-to": "content/post/2018/03/25/"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
