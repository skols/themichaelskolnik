{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Learn Maching Learning* series on Kaggle\n",
    "I went through the level 1 *Learn Machine Learning* series on Kaggle using Python (https://www.kaggle.com/learn/machine-learning). The data used is from the [*Home Prices: Advanced Regression Techniques*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
      "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
      "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
      "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
      "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
      "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
      "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
      "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
      "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
      "\n",
      "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
      "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
      "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
      "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
      "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
      "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
      "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
      "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
      "\n",
      "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
      "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
      "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
      "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
      "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
      "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
      "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
      "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
      "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
      "\n",
      "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
      "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
      "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
      "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
      "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
      "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
      "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
      "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
      "\n",
      "           SalePrice  \n",
      "count    1460.000000  \n",
      "mean   180921.195890  \n",
      "std     79442.502883  \n",
      "min     34900.000000  \n",
      "25%    129975.000000  \n",
      "50%    163000.000000  \n",
      "75%    214000.000000  \n",
      "max    755000.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save filepath to variable\n",
    "training_data_filepath = \"C:/Development/Kaggle/House Prices - Advanced Regression Techniques/train.csv\"\n",
    "\n",
    "# Read the data and store in a dataframe called training_set\n",
    "training_set = pd.read_csv(training_data_filepath)\n",
    "\n",
    "# Print a summary of the data in training_set\n",
    "print(training_set.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the columns in training_set\n",
    "print(training_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    208500\n",
      "1    181500\n",
      "2    223500\n",
      "3    140000\n",
      "4    250000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Store the series of prices separately as training_price_data\n",
    "training_price_data = training_set.SalePrice\n",
    "\n",
    "# Print the first 5 records\n",
    "print(training_price_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             LotArea    YearBuilt\n",
      "count    1460.000000  1460.000000\n",
      "mean    10516.828082  1971.267808\n",
      "std      9981.264932    30.202904\n",
      "min      1300.000000  1872.000000\n",
      "25%      7553.500000  1954.000000\n",
      "50%      9478.500000  1973.000000\n",
      "75%     11601.500000  2000.000000\n",
      "max    215245.000000  2010.000000\n"
     ]
    }
   ],
   "source": [
    "# Create a list with the columns I am interested in\n",
    "columns_of_interest = [\"LotArea\", \"YearBuilt\"]\n",
    "\n",
    "# Create a dataframe with just those columns\n",
    "training_two_columns = training_set[columns_of_interest]\n",
    "\n",
    "# Print a summary of the training_two_columns dataframe\n",
    "print(training_two_columns.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target variable and call it y\n",
    "y = training_set.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the predictor variables\n",
    "predictors = [\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\"]\n",
    "\n",
    "# Create a new dataframe with the predictors list\n",
    "X = training_set[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define the model\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "tree_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the first 10 houses\n",
      "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "0     8450       2003       856       854         2             3   \n",
      "1     9600       1976      1262         0         2             3   \n",
      "2    11250       2001       920       866         2             3   \n",
      "3     9550       1915       961       756         1             3   \n",
      "4    14260       2000      1145      1053         2             4   \n",
      "5    14115       1993       796       566         1             1   \n",
      "6    10084       2004      1694         0         2             3   \n",
      "7    10382       1973      1107       983         2             3   \n",
      "8     6120       1931      1022       752         2             2   \n",
      "9     7420       1939      1077         0         1             2   \n",
      "\n",
      "   TotRmsAbvGrd  \n",
      "0             8  \n",
      "1             6  \n",
      "2             6  \n",
      "3             7  \n",
      "4             9  \n",
      "5             5  \n",
      "6             7  \n",
      "7             7  \n",
      "8             8  \n",
      "9             5  \n",
      "The predictions are:\n",
      "[208500. 181500. 223500. 140000. 250000. 143000. 307000. 200000. 129900.\n",
      " 118000.]\n"
     ]
    }
   ],
   "source": [
    "# Make some predictions\n",
    "print(\"Making predictions for the first 10 houses\")\n",
    "print(X.head(n=10))\n",
    "print(\"The predictions are:\")\n",
    "print(tree_model.predict(X.head(n=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.35433789954339"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = tree_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem with \"in-sample\" scores\n",
    "The mean absolute error we just computed can be called an \"in-sample\" score. We used a single set of houses (called a data sample) for both building the model and for calculating it's MAE score. This is bad.\n",
    "\n",
    "Imagine that, in the large real estate market, door color is unrelated to home price. However, in the sample of data you used to build the model, it may be that all homes with green doors were very expensive. The model's job is to find patterns that predict home prices, so it will see this pattern, and it will always predict high prices for homes with green doors.\n",
    "\n",
    "Since this pattern was originally derived from the training data, the model will appear accurate in the training data.\n",
    "\n",
    "But this pattern likely won't hold when the model sees new data, and the model would be very inaccurate (and cost us lots of money) when we applied it to our real estate business.\n",
    "\n",
    "Even a model capturing only happenstance relationships in the data, relationships that will not be repeated when new data, can appear to be very accurate on in-sample accuracy measurements.\n",
    "\n",
    "### Create validation data using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30743.750684931507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and validation data,\n",
    "# for both predictors and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script. It can be any number; I'm choosing 42.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted prices on validation data\n",
    "predictions_val = tree_model.predict(X_val)\n",
    "print(mean_absolute_error(y_val, predictions_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling underfitting vs. overfitting\n",
    "The *max_leaf_nodes* argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area to the overfitting area.\n",
    "\n",
    "Create a utility function to help compare MAE scores from differevalues for *max_leaf_nodes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, predictors_train, val_predictors, targ_train, targ_val):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=42)\n",
    "    model.fit(predictors_train, targ_train)\n",
    "    preds_val = model.predict(val_predictors)\n",
    "    mae = mean_absolute_error(targ_val, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5 \t\t Mean Absolute Error: 35244.94032482636\n",
      "Max leaf nodes: 10 \t\t Mean Absolute Error: 31256.15612179911\n",
      "Max leaf nodes: 25 \t\t Mean Absolute Error: 29611.012298361497\n",
      "Max leaf nodes: 50 \t\t Mean Absolute Error: 27232.09960472095\n",
      "Max leaf nodes: 100 \t\t Mean Absolute Error: 27021.244092878136\n",
      "Max leaf nodes: 200 \t\t Mean Absolute Error: 29015.822642629737\n",
      "Max leaf nodes: 500 \t\t Mean Absolute Error: 31450.856430996708\n",
      "Max leaf nodes: 1000 \t\t Mean Absolute Error: 31717.233789954334\n",
      "Max leaf nodes: 5000 \t\t Mean Absolute Error: 31724.594520547944\n"
     ]
    }
   ],
   "source": [
    "for max_leaf_nodes in [5, 10, 25, 50, 100, 200, 500, 1000, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, X_train, X_val, y_train, y_val)\n",
    "    print(\"Max leaf nodes: {0} \\t\\t Mean Absolute Error: {1}\".format(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22697.165414220482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_preds = forest_model.predict(X_val)\n",
    "print(mean_absolute_error(y_val, forest_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "front-matter": {
   "date": "2018-03-15",
   "slug": "home-prices-python",
   "subtitle": "",
   "title": "My work on the data from Kaggle's Learn Maching Learning series"
  },
  "hugo-jupyter": {
   "render-to": "content/post/2018/03/18/"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
