{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 *Learn Maching Learning* series on Kaggle\n",
    "This is the level 2 part of the *Learn Machine Learning* series on Kaggle using Python (https://www.kaggle.com/learn/machine-learning). The data used is from the [*Home Prices: Advanced Regression Techniques*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) competition.\n",
    "\n",
    "Like the post for level 1, this post will show the section name, my code from the corresponding section for the instructions under **Your Turn**, and some brief notes on what is taught in each section.\n",
    "\n",
    "First I'll run the necessary code from before and add a new function, score_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Save filepath to variable\n",
    "training_data_filepath = \"C:/Development/Kaggle/House Prices - Advanced \\\n",
    "Regression Techniques/train.csv\"\n",
    "\n",
    "# Read the data and store in a dataframe called training_set\n",
    "training_set = pd.read_csv(training_data_filepath)\n",
    "\n",
    "# Select the target variable and call it y\n",
    "y = training_set.SalePrice\n",
    "\n",
    "# Create the dataframe with only numeric predictors, dropping Id and SalePrice\n",
    "X = training_set.drop([\"Id\", \"SalePrice\"], axis=1)\\\n",
    "        .select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "# Split data into training and validation data, for both predictors and\n",
    "# target.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,\n",
    "                                                 train_size=0.7,\n",
    "                                                 test_size=0.3)\n",
    "\n",
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "[Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values)\n",
    "\n",
    "This section teaches multiple approaches for dealing with missing data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass         0\n",
      "LotFrontage      259\n",
      "LotArea            0\n",
      "OverallQual        0\n",
      "OverallCond        0\n",
      "YearBuilt          0\n",
      "YearRemodAdd       0\n",
      "MasVnrArea         8\n",
      "BsmtFinSF1         0\n",
      "BsmtFinSF2         0\n",
      "BsmtUnfSF          0\n",
      "TotalBsmtSF        0\n",
      "1stFlrSF           0\n",
      "2ndFlrSF           0\n",
      "LowQualFinSF       0\n",
      "GrLivArea          0\n",
      "BsmtFullBath       0\n",
      "BsmtHalfBath       0\n",
      "FullBath           0\n",
      "HalfBath           0\n",
      "BedroomAbvGr       0\n",
      "KitchenAbvGr       0\n",
      "TotRmsAbvGrd       0\n",
      "Fireplaces         0\n",
      "GarageYrBlt       81\n",
      "GarageCars         0\n",
      "GarageArea         0\n",
      "WoodDeckSF         0\n",
      "OpenPorchSF        0\n",
      "EnclosedPorch      0\n",
      "3SsnPorch          0\n",
      "ScreenPorch        0\n",
      "PoolArea           0\n",
      "MiscVal            0\n",
      "MoSold             0\n",
      "YrSold             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detect which columns have missing values\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from dropping columns with missing values:\n",
      "17760.797792998477\n"
     ]
    }
   ],
   "source": [
    "# Get model score from dropping columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"Mean Absolute Error from dropping columns with missing values:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation:\n",
      "18445.657762557075\n"
     ]
    }
   ],
   "source": [
    "# Get model score from Imputation\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "\n",
    "# \"fit_transform\" is the training step. It \"learns\" based upon the training set data.\n",
    "# \"transform\" uses the newly trained model to make predictions on the \"test set\"\n",
    "# (a.k.a. \"validation set\" in the the first tutorial).\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation while tracking what was imputed:\n",
      "18617.85372907154\n"
     ]
    }
   ],
   "source": [
    "# Get model score from Imputation with extra columns showing what was imputed\n",
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "\n",
    "cols_with_missing = (col for col in X_train.columns\n",
    "                    if X_train[col].isnull().any())\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + \"_was_missing\"] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + \"_was_missing\"] = imputed_X_test_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\n",
    "imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation while tracking what was imputed:\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2\n",
    "[Using Categorical Data with One Hot Encoding](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding)\n",
    "\n",
    "In this section you learn how to handle categorical data by using one hot encoding, which creates new columns for each value in the categorical field. The new columns will have either a 1 or 0 in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error with Imputation and One Hot Encoding:\n",
      "19233.457077625568\n"
     ]
    }
   ],
   "source": [
    "# Using cardinality as a way to select categorical data. \"cardinality\" means\n",
    "# the number of unique values in a column.\n",
    "candidate_train_predictors = training_set.drop([\"Id\", \"SalePrice\"], axis=1)\n",
    "\n",
    "low_cardinality_cols = [cname for cname in candidate_train_predictors if\n",
    "                       candidate_train_predictors[cname].nunique() < 10 and\n",
    "                       candidate_train_predictors[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in candidate_train_predictors if\n",
    "               candidate_train_predictors[cname].dtype in\n",
    "                [\"int64\", \"float64\"]]\n",
    "\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X = candidate_train_predictors[my_cols]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "# Using one hot encoding the categorical variables\n",
    "X_train_one_hot_encoded = pd.get_dummies(X_train)\n",
    "X_test_one_hot_encoded = pd.get_dummies(X_test)\n",
    "\n",
    "# Make sure the columns show up in the same order by using the align method\n",
    "# \"join='inner'\" is like an inner join in SQL, keeping only the columns in\n",
    "# both datasets\n",
    "X_train_final, X_test_final = X_train_one_hot_encoded.align(\n",
    "    X_test_one_hot_encoded,\n",
    "    join=\"inner\",\n",
    "    axis=1)\n",
    "\n",
    "# Impute the missing data\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train_final)\n",
    "imputed_X_test = my_imputer.transform(X_test_final)\n",
    "\n",
    "# Show model score\n",
    "print(\"Mean Absolute Error with Imputation and One Hot Encoding:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3\n",
    "[Learning to Use XGBoost](https://www.kaggle.com/dansbecker/learning-to-use-xgboost)\n",
    "\n",
    "This section covers XGBoost, the leading model for working with standard tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\micha\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(imputed_X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Mean Absolute Error:16458.5521814355\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "xgb_predictions = xgb_model.predict(imputed_X_test)\n",
    "\n",
    "print(\"XGBoost Mean Absolute Error:\" + \n",
    "      str(mean_absolute_error(xgb_predictions, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_score: 27433.203125\n",
      "Model best_iteration: 87\n",
      "Model best_ntree_limit:88\n"
     ]
    }
   ],
   "source": [
    "# Tune the model by adding n_estimators and early_stopping_rounds\n",
    "xgb_model = XGBRegressor(n_estimators=1000)\n",
    "xgb_model.fit(imputed_X_train, y_train, early_stopping_rounds=20,\n",
    "              eval_set=[(imputed_X_test, y_test)], verbose=False)\n",
    "\n",
    "print(\"Model best_score: \" + str(xgb_model.best_score))\n",
    "print(\"Model best_iteration: \" + str(xgb_model.best_iteration))\n",
    "print(\"Model best_ntree_limit:\" + str(xgb_model.best_ntree_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Mean Absolute Error with best_iteration: 16450.916060216896\n",
      "XGBoost Mean Absolute Error with best_ntree_limit: 16445.990261130137\n"
     ]
    }
   ],
   "source": [
    "# Run the model with the best_iteration and best_ntree_limit, then predict\n",
    "xgb_model_bi = XGBRegressor(n_estimators=87)\n",
    "xgb_model_bi.fit(imputed_X_train, y_train,\n",
    "              eval_set=[(imputed_X_test, y_test)], verbose=False)\n",
    "\n",
    "xgb_predictions_bi = xgb_model_bi.predict(imputed_X_test)\n",
    "\n",
    "xgb_model_bnl = XGBRegressor(n_estimators=88)\n",
    "xgb_model_bnl.fit(imputed_X_train, y_train,\n",
    "              eval_set=[(imputed_X_test, y_test)], verbose=False)\n",
    "\n",
    "xgb_predictions_bnl = xgb_model_bnl.predict(imputed_X_test)\n",
    "\n",
    "print(\"XGBoost Mean Absolute Error with best_iteration: \" + \n",
    "      str(mean_absolute_error(xgb_predictions_bi, y_test)))\n",
    "print(\"XGBoost Mean Absolute Error with best_ntree_limit: \" + \n",
    "      str(mean_absolute_error(xgb_predictions_bnl, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4\n",
    "[Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-dependence-plots)\n",
    "\n",
    "This section explains how extract insights from your models using partial dependence plots, which show how each variable or predictor affects the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns X and y\n",
    "def get_data(df, cols_to_use):\n",
    "    y = df.SalePrice\n",
    "    X = df[cols_to_use]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        random_state=42)\n",
    "    my_imputer = Imputer()\n",
    "    imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "    imputed_X_test = my_imputer.fit_transform(X_test)\n",
    "    return imputed_X_train, imputed_X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Create a list of three predictor variables\n",
    "predictors = [\"LotArea\", \"YearBuilt\", \"TotRmsAbvGrd\"]\n",
    "\n",
    "# Call the function\n",
    "X_train, X_test, y_train, y_test = get_data(training_set, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAADPCAYAAABhsw86AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMIQMJugZDAaDIWT4f8xSgm5/Tm6eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26280d63f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "my_model = GradientBoostingRegressor()\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "# Hypotheses for each predictor\n",
    "# As LotArea increases, SalePrice increases\n",
    "# As YearBuilt increases, SalePrice increases\n",
    "# As TotRmsAbvGrd increases, SalePrice increases\n",
    "my_plots = plot_partial_dependence(my_model,\n",
    "                                  features=[0, 1, 2],\n",
    "                                  X=X_train,\n",
    "                                  feature_names=[\"LotArea\",\n",
    "                                                 \"YearBuilt\",\n",
    "                                                 \"TotRmsAbvGrd\"],\n",
    "                                  grid_resolution=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a certain LotArea, SalePrice begins to decrease. With YearBuilt, there is a leveling off for about 20 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5\n",
    "[Pipelines](https://www.kaggle.com/dansbecker/pipelines)\n",
    "\n",
    "This section covers pipelines and how they make your code cleaner and more professional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data with one hot encoding\n",
    "candidate_train_predictors = training_set.drop([\"Id\", \"SalePrice\"], axis=1)\n",
    "\n",
    "low_cardinality_cols = [cname for cname in candidate_train_predictors if\n",
    "                       candidate_train_predictors[cname].nunique() < 10 and\n",
    "                       candidate_train_predictors[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in candidate_train_predictors if\n",
    "               candidate_train_predictors[cname].dtype in\n",
    "                [\"int64\", \"float64\"]]\n",
    "\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X = candidate_train_predictors[my_cols]\n",
    "y = training_set.SalePrice\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "# Using one hot encoding the categorical variables\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Make sure the columns show up in the same order by using the align method\n",
    "# \"join='inner'\" is like an inner join in SQL, keeping only the columns in\n",
    "# both datasets\n",
    "X_train, X_test = X_train_one_hot_encoded.align(\n",
    "    X_test_one_hot_encoded,\n",
    "    join=\"inner\",\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolue Error: 18159.600684931505\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "my_pipeline = make_pipeline(Imputer(), RandomForestRegressor())\n",
    "\n",
    "# Fit and predict using the pipeline\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "predictions = my_pipeline.predict(X_test)\n",
    "\n",
    "# Print MAE\n",
    "print(\"Mean Absolue Error: \" + str(mean_absolute_error(predictions, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6\n",
    "[Cross-Validation](https://www.kaggle.com/dansbecker/cross-validation)\n",
    "\n",
    "This section covers cross-validation, which gives you a more reliable measure of your model's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data and make the pipeline\n",
    "y = training_set.SalePrice\n",
    "\n",
    "predictors = [\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\",\n",
    "              \"BedroomAbvGr\", \"TotRmsAbvGrd\"]\n",
    "\n",
    "X = training_set[predictors]\n",
    "\n",
    "my_pipeline = make_pipeline(Imputer(), RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-23619.64847463 -24044.31307324 -25411.42688615]\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Get the cross-validation scores\n",
    "scores = cross_val_score(my_pipeline, X, y,\n",
    "                         scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 24358.4628113363\n"
     ]
    }
   ],
   "source": [
    "# Print the average of the scores to get a single measure\n",
    "print(\"Mean Absolute Error: {0}\".format(-1 * scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-31607.33867214 -28752.41276523 -30952.68010288]\n",
      "Mean Absolute Error: 30437.477180084108\n"
     ]
    }
   ],
   "source": [
    "# Remove YearBuilt and rerun\n",
    "predictors = [\"LotArea\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\",\n",
    "              \"BedroomAbvGr\", \"TotRmsAbvGrd\"]\n",
    "\n",
    "X = training_set[predictors]\n",
    "\n",
    "scores = cross_val_score(my_pipeline, X, y,\n",
    "                         scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean Absolute Error: {0}\".format(-1 * scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-19261.77241615 -18868.2174538  -20048.12942387]\n",
      "Mean Absolute Error: 19392.70643127347\n"
     ]
    }
   ],
   "source": [
    "# Use all numeric fields and rerun\n",
    "X = training_set.drop([\"Id\", \"SalePrice\"], axis=1)\\\n",
    "        .select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "scores = cross_val_score(my_pipeline, X, y,\n",
    "                         scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean Absolute Error: {0}\".format(-1 * scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 7\n",
    "[Data Leakage](https://www.kaggle.com/dansbecker/data-leakage)\n",
    "\n",
    "This section covers how to identify and avoid data leakage, one of the most common and costly mistakes in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-19986.84188912 -18771.71396304 -19436.84814815]\n",
      "Mean Absolute Error: 19398.468000101402\n"
     ]
    }
   ],
   "source": [
    "# Create the data, make the pipeline, and get the accuracy cross-validation\n",
    "# score\n",
    "y = training_set.SalePrice\n",
    "\n",
    "predictors = [\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\",\n",
    "              \"BedroomAbvGr\", \"TotRmsAbvGrd\"]\n",
    "\n",
    "X = training_set.drop([\"Id\", \"SalePrice\"], axis=1)\\\n",
    "        .select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "my_pipeline = make_pipeline(Imputer(), RandomForestRegressor())\n",
    "\n",
    "scores = cross_val_score(my_pipeline, X, y,\n",
    "                         scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean Absolute Error: {0}\".format(-1 * scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-18974.61902806 -20104.03839836 -20104.8617284 ]\n",
      "Mean Absolute Error with leaks removed: 19727.839718271774\n"
     ]
    }
   ],
   "source": [
    "# Identify some potential leaks and run after removing them\n",
    "# Most datasets from Kaggle competitions don't have variables that cause\n",
    "# data leakage, but I'm choosing some that I think might.\n",
    "potential_leaks = [\"MiscVal\", \"MoSold\", \"YrSold\"]\n",
    "\n",
    "X2 = X.drop(potential_leaks, axis=1)\n",
    "\n",
    "scores = cross_val_score(my_pipeline, X2, y,\n",
    "                         scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean Absolute Error with leaks removed: {0}\"\\\n",
    "      .format(-1 * scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE is higher after the leaks are removed but that makes sense. That doesn't mean those variables were leaks, but they did help with prediction. They may not have been that valid though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wraps up the level 2 part of the *Learn Machine Learning* series on Kaggle. The way this level is structured, it doesn't make sense to have one place for all the code; it makes more sense to me to keep it all separate.\n",
    "Also, it took me a little over a week to start and finish, which I don't think is too bad considering I had aimed for a week or less. I now know that a week is an achievable goal for posts like this. Some may take less, others more. Like I said in the level 1 post, next I'm going to recreate these tutorials in R. Those don't exist on Kaggle, so I'm looking forward to the challenge!"
   ]
  }
 ],
 "metadata": {
  "front-matter": {
   "date": "2018-04-03",
   "slug": "home-prices-python-2",
   "subtitle": "",
   "title": "My code from the exercises of Level 2 of Kaggle's Learn Maching Learning series"
  },
  "hugo-jupyter": {
   "render-to": "content/post/2018/04/01"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
